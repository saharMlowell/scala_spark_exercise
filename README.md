# scala_spark_exercise
https://ntoggle.atlassian.net/browse/PLAT-1831<br>
1- having simple people.json file, name, age and city<br>
2- load data with spark as dataFrame<br>
3- filter (spark) on a col, make a query, find ppl less than some age. //df.filter(age < 50).select('name')<br>
4- output the result<br>
5- save to parquet data set<br>

test2